{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Nhóm 14 Master:  CodeBert base + Distilbert baseline\n\n**Thành viên:**\n\n19120212 - Vũ Công Duy\n\n19120301 - Võ Thành Nam\n\n19120389 - Tô Gia Thuận\n\n19120459 - Hồ Anh Bình\n","metadata":{}},{"cell_type":"markdown","source":"**Lưu ý**: Trên thực tế, để có thể tối ưu hóa điểm số đạt được và tối ưu hóa được thời gian cho phép sử dụng GPU trên Kaggle để huấn luyện, nhóm quyết định chia bài làm thành 3 file notebook để thực hiện. Nhưng trong yêu cầu bài nộp chỉ giới hạn việc nộp 1 file ipynb cộng thêm việc không thể nộp kèm theo file model đã train sẵn. Nên trong bài nộp này nhóm tổng hợp lại cả 3 file notebook thành 1 file notebook duy nhất.","metadata":{}},{"cell_type":"markdown","source":"# Bài toán\n\nMục tiêu của bài toán là sắp xếp chính xác thứ tự của các cell trong file, với thông tin cho trước là giữa những code cell đã đảm bảo thứ tự đúng. Dễ hiểu hơn, ta có ví dụ sau.\n\nMột file chưa có thứ tự đúng:\n```\ncode_1\ncode_2\ncode_3\nmarkdown_1\nmarkdown_2\n```\nvà một file đã có thứ tự đúng:\n```\ncode_1\nmarkdown_2\ncode_2\ncode_3\nmarkdown_1\n```\nCác markdown cell có thể ở bất kì thứ tự nào, nhưng giữa các code cell thì sẽ không có trường hợp `code_2` ở trước `code_1`.","metadata":{}},{"cell_type":"markdown","source":"# Ý tưởng chính","metadata":{}},{"cell_type":"markdown","source":"Vị trí của một cell trong notebook sẽ được biễu diễn bằng tham số `rank`.  \nNếu cell đó là cell đầu tiên của notebook thì `rank` mang giá trị 1, cell phía dưới thì `rank` là 2,...   \n`rank_pct` chính là tham số chuẩn hoá cho `rank` với mục đích giới hạn giá trị này luôn dưới 1 bằng cách lấy `rank` chia cho tổng số cell của notebook.  \n**Output** của mạng neural cũng là `rank_pct` của mỗi cell.  \n**Input** sẽ được giải thích ở bên dưới.  ","metadata":{}},{"cell_type":"markdown","source":"# CodeBert","metadata":{}},{"cell_type":"markdown","source":"`code-bert` là một mạng BERT với đầu vào gồm 1 chuỗi ngôn ngữ tự nhiên và 1 chuỗi ngôn ngữ lập trình.  \nChuỗi ngôn ngữ tự nhiên trong trường hợp này sẽ là dữ liệu của file notebook đang xét và chuỗi ngôn ngữ lập trình chính là dữ liệu của tất cả các cell code trong file notebook. Cấu trúc sẽ là :  \n`<markdown><s><code1><s><code2><s>....<code_n>`  với `<s>` là kí tự dùng để phân cách.   \nTrong quá trình làm, bọn em sẽ có vài thao tác tiền xử lý để tối ưu như : giới hạn độ dài chuỗi markdown, giới hạn độ dài chuỗi code bằng cách chọn random có quy luật,...  ","metadata":{}},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"#from dataset import *\nfrom typing import List\nimport json\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nfrom scipy import sparse\nfrom random import sample\nfrom importlib.resources import path\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport sys, os\n\nimport argparse\nfrom bisect import bisect\nimport gc\nimport nltk \nfrom nltk.corpus import stopwords\nimport re\n\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metric \n","metadata":{}},{"cell_type":"code","source":"def count_inversions(a):\n    inversions = 0\n    sorted_so_far = []\n    for i, u in enumerate(a):\n        j = bisect(sorted_so_far, u)\n        inversions += i - j\n        sorted_so_far.insert(j, u)\n    return inversions\n\n\ndef kendall_tau(ground_truth, predictions):\n    total_inversions = 0\n    total_2max = 0  # twice the maximum possible inversions across all instances\n    for gt, pred in zip(ground_truth, predictions):\n        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n        total_inversions += count_inversions(ranks)\n        n = len(gt)\n        total_2max += n * (n - 1)\n    return 1 - 4 * total_inversions / total_2max","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"data_dir = Path('..//input/AI4Code') # đường dẫn đến input\nBATCH_SIZE = 16 #kích thước batch trong mỗi lần train\nNW = 2 # số worker dùng để load dataset\nEPOCHS = 3 # số epochs để huấn luyên mô hình\nACCUMULATE = 4 # chỉ số trong thuật toán tối ưu adam\nDEFAULT_MODEL ='../input/huggingface-code-models/codebert-base' # đường dẫn đến mạng code-bert đã học sẵn ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(\"./data\"):\n    os.mkdir(\"./data\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"markdown","source":"Load 100 % số file dùng để train. Tham số `percent = 1` thể hiện điều đó.\n\n**Trên thực tế**, nhóm chỉ thực hiện load 15 % lượng file để train (`percent = 0.15`) bởi vì giới hạn về mặt phần cứng trên Kaggle","metadata":{}},{"cell_type":"code","source":"def read_notebook(path):\n    '''\n    path : path to notebook file .json\n    return : dataframe of notebook. each row inform a cell in notebok\n    '''\n    return (\n        pd.read_json(\n            path,\n            dtype={'cell_type': 'category', 'source': 'str'})\n            .assign(id=path.stem)\n            .rename_axis('cell_id')\n    )\n\npercent = 1\npaths_train = list((data_dir / 'train').glob('*.json'))\npaths_train = paths_train[:int(len(paths_train)*percent)]\nprint('Loading training data ...')\nnotebooks_train = [\n    read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n]\ndf = (\n    pd.concat(notebooks_train)\n        .set_index('id', append=True)\n        .swaplevel()\n        .sort_index(level='id', sort_remaining=False)\n)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess, integrate, split data\n","metadata":{}},{"cell_type":"markdown","source":"## Integrate","metadata":{}},{"cell_type":"code","source":"#test\npd.read_json('../input/AI4Code/train/8a2564b730a575.json',\n             dtype={'cell_type': 'category', 'source': 'str'}\n            ).assign(id=\"8a2564b730a575\").rename_axis('cell_id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_orders = pd.read_csv(\n    data_dir / 'train_orders.csv',\n    index_col='id',\n    squeeze=True,\n).str.split() \n# Split the string representation of cell_ids into a list\n\ndf_orders_ = df_orders.to_frame().join(\n    df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n    how='right',\n)\ndf_orders","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing\n\nThêm thông tin về thứ tự các cell bằng cột `rank` và chuẩn hóa về khoảng `0-1` ở cột `pct_rank`.","metadata":{}},{"cell_type":"code","source":"def get_ranks(base, derived):\n    '''\n    return a rank collumn for nb (notebook)\n    nb : df of notebook\n    cell_order: order of cell in notebook\n    '''\n    return [base.index(d) for d in derived]\n\nranks = {}\nfor id_, cell_order, cell_id in df_orders_.itertuples():\n    ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\ndf_ranks = (\n    pd.DataFrame\n        .from_dict(ranks, orient='index')\n        .rename_axis('id')\n        .apply(pd.Series.explode)\n        .set_index('cell_id', append=True)\n)\ndf_ranks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = (\n    df.reset_index()\n    .merge(df_ranks, on=[\"id\", \"cell_id\"])\n    .merge(df_ancestors, on=[\"id\"])\n)\ndf[\"pct_rank\"] = df[\"rank\"] / df.groupby(\"id\")[\"cell_id\"].transform(\"count\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split data train, test, val","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupShuffleSplit\n\nNVALID = 0.1  # size of validation set\nsplitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\ntrain_ind, val_ind = next(splitter.split(df, groups=df[\"ancestor_id\"]))\ntrain_df = df.loc[train_ind].reset_index(drop=True)\nval_df = df.loc[val_ind].reset_index(drop=True)\n\ntrain_df_mark = train_df[train_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)\nval_df_mark = val_df[val_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lưu lại các file data sau khi split phòng trường hợp cần sử dụng lại","metadata":{}},{"cell_type":"code","source":"train_df_mark.to_csv(\"./data/train_mark.csv\", index=False)\nval_df_mark.to_csv(\"./data/val_mark.csv\", index=False)\nval_df.to_csv(\"./data/val.csv\", index=False)\ntrain_df.to_csv(\"./data/train.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing: clean code\ndef clean_code(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.replace('[', ' ').replace(']', ' ').replace('(', ' ').replace(')', ' ').replace('{', ' ').replace('}', ' ').replace('=', ' ').replace(',', ' ')\n    text = text.lower()\n    text = text.replace('_', '')\n    text = text.replace('\\n', ' ')\n    text = text.replace('.', ' ')\n    text = re.sub(r'\".*\"', ' ', text)\n    text = re.sub(r\"'.*'\", ' ', text)\n    text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", ' ', text)\n    text = re.sub(' +', ' ', text)\n    text = text.strip()\n    return text\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features extraction\n\nThực hiện trích xuất các đặc trưng bao gồm:\n- Số lượng code cell.\n- Số lượng markdown cell.\n- 20 code cell được lấy cách đều nhau.","metadata":{}},{"cell_type":"code","source":"def sample_cells(cells, n):\n    cells = [str(cell).replace(\"\\\\n\", \"\\n\") for cell in cells]\n#     cells = [code_preprocessing(cell) for cell in cells]\n    \n    if n >= len(cells):\n        return [cell[:200] for cell in cells]\n    else:\n        results = []\n        step = len(cells) / n\n        idx = 0\n        while int(np.round(idx)) < len(cells):\n            results.append(cells[int(np.round(idx))])\n            idx += step\n        assert cells[0] in results\n        if cells[-1] not in results:\n            results[-1] = cells[-1]\n        return results\n\ndf = val_df\ndef get_features(df):\n    features = dict()\n    df = df.sort_values(\"rank\").reset_index(drop=True)\n    for idx,sub_df in tqdm(df.groupby(\"id\")):\n        features[idx] = dict()\n        total_md = sub_df[sub_df['cell_type']=='markdown'].shape[0]\n        code_sub_df = sub_df[sub_df['cell_type']=='code']\n        total_code = code_sub_df.shape[0]\n        codes = sample_cells(code_sub_df['source'].values,20)\n        features[idx]['total_code']= total_code\n        features[idx]['total_md'] = total_md\n        features[idx]['codes'] = codes\n    return features\n\nval_fts = get_features(val_df)\ntrain_fts = get_features(train_df)\n\n#save file\njson.dump(val_fts, open(\"./data/val_fts.json\",\"wt\"))\njson.dump(train_fts, open(\"./data/train_fts.json\",\"wt\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define MarkdownModel class\n\nThứ tự các layer bao gồm:\n- CodeBert\n- Linear(769,1)\nLinear layer có kích thước 769 vì có thêm 1 giá trị đặc trưng được thêm vào sau khi đi qua CodeBert.","metadata":{}},{"cell_type":"code","source":"from bisect import bisect\n\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch\nfrom transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup, AutoConfig\n\n\nclass MarkdownModel(nn.Module):\n    def __init__(self, model_path = DEFAULT_MODEL):\n        super(MarkdownModel, self).__init__()\n        self.config = AutoConfig.from_pretrained(model_path, output_hidden_states=True)\n        self.model = AutoModel.from_pretrained(model_path)\n#         self.dropout = nn.Dropout(p=0.1)\n        self.top = nn.Linear(769, 1)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n\n    def forward(self, ids, mask, fts):\n        x = self.model(ids, mask)[0]\n        x = torch.cat((x[:, 0, :], fts), 1)\n        x = self.top(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define MarkdownDataset class\n\n- `total_max_len` là kích thước tối đa của encode.\n- `md_max_len là ","metadata":{}},{"cell_type":"code","source":"class MarkdownDataset(Dataset):\n\n    def __init__(self, df, total_max_len, md_max_len, fts, model_name_or_path = DEFAULT_MODEL):\n        super().__init__()\n        self.df = df.reset_index(drop=True)\n        self.md_max_len = md_max_len\n        self.total_max_len = total_max_len  # maxlen allowed by model config\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n        self.fts = fts\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        inputs = self.tokenizer.encode_plus(\n            row.source,\n            None,\n            add_special_tokens=True,\n            max_length=self.md_max_len,\n            padding=\"max_length\",\n            return_token_type_ids=True,\n            truncation=True\n        )\n        code_inputs = self.tokenizer.batch_encode_plus(\n            [str(x) for x in self.fts[row.id][\"codes\"]],\n            add_special_tokens=True,\n            max_length=23,\n            padding=\"max_length\",\n            truncation=True\n        )\n        n_md = self.fts[row.id][\"total_md\"]\n        n_code = self.fts[row.id][\"total_code\"]\n        if n_md + n_code == 0:\n            fts = torch.FloatTensor([0])\n        else:\n            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n\n        ids = inputs['input_ids']\n        for x in code_inputs['input_ids']:\n            ids.extend(x[:-1])\n        ids = ids[:self.total_max_len]\n        if len(ids) != self.total_max_len:\n            ids = ids + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(ids))\n        ids = torch.LongTensor(ids)\n\n        mask = inputs['attention_mask']\n        for x in code_inputs['attention_mask']:\n            mask.extend(x[:-1])\n        mask = mask[:self.total_max_len]\n        if len(mask) != self.total_max_len:\n            mask = mask + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(mask))\n        mask = torch.LongTensor(mask)\n\n        assert len(ids) == self.total_max_len\n\n        return ids, mask, fts, torch.FloatTensor([row.pct_rank])\n\n    def __len__(self):\n        return self.df.shape[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# order_df = pd.read_csv(data_dir/ \"train_orders.csv\").set_index(\"id\")\ndf_orders = pd.read_csv(\n    data_dir / 'train_orders.csv',\n    index_col='id',\n    squeeze=True,\n).str.split()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df_mark = pd.read_csv(\"./data/train_mark.csv\").drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n# train_fts = json.load(open(\"./data/train_fts.json\"))\n# train_df_mark = pd.read_csv(\"./data/val_mark.csv\").drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n# val_fts = json.load(open(\"./data/val_fts.json\"))\n# val_df = pd.read_csv(\"./data/val.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define dataset instance","metadata":{}},{"cell_type":"code","source":"train_ds = MarkdownDataset(\n    df = train_df_mark,\n    fts = json.load(open('./data/train_fts.json')),\n    total_max_len=512,\n    md_max_len= 64,\n)\nval_ds = MarkdownDataset(\n    df = val_df_mark,\n    fts = json.load(open('./data/val_fts.json')),\n    total_max_len=512,\n    md_max_len= 64,\n)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NW,\n                          pin_memory=False, drop_last=True)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NW,\n                        pin_memory=False, drop_last=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data(data):\n    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n\n\ndef validate(model, val_loader):\n    model.eval()\n\n    tbar = tqdm(val_loader, file=sys.stdout)\n\n    preds = []\n    labels = []\n\n    with torch.no_grad():\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            with torch.cuda.amp.autocast():\n                pred = model(*inputs)\n\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n    \n    return np.concatenate(labels), np.concatenate(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train cell","metadata":{}},{"cell_type":"code","source":"# from torch.optim import Optimizer\n\ndef train(model, train_loader, val_loader, epochs):\n#     wandb.init()\n    np.random.seed(0)\n    # Creating optimizer and lr schedulers\n    param_optimizer = list(model.named_parameters())\n    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n#     no_decay = ['bias', 'gamma', 'beta']\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n    ]\n\n    num_train_optimization_steps = int(EPOCHS * len(train_loader) / ACCUMULATE)\n    optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5,\n                      correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n    \n#     optimizer = bnb.optim.AdamW8bit(optimizer_grouped_parameters, lr=3e-5)\n#     optimizer = BertAdam(optimizer_grouped_parameters,lr=2e-5,warmup=.1)\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.05 * num_train_optimization_steps,\n                                                num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n\n    criterion = torch.nn.L1Loss()\n    scaler = torch.cuda.amp.GradScaler()\n\n    for e in range(epochs):\n        model.train()\n        tbar = tqdm(train_loader, file=sys.stdout)\n        loss_list = []\n        preds = []\n        labels = []\n\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            with torch.cuda.amp.autocast():\n                pred = model(*inputs)\n                loss = criterion(pred, target)\n            scaler.scale(loss).backward()\n            if idx % ACCUMULATE == 0 or idx == len(tbar) - 1:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n                scheduler.step()\n\n            loss_list.append(loss.detach().cpu().item())\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n\n            avg_loss = np.round(np.mean(loss_list), 4)\n\n            tbar.set_description(f\"Epoch {e + 1} Loss: {avg_loss} lr: {scheduler.get_last_lr()}\")\n            \n\n        y_val, y_pred = validate(model, val_loader)\n        val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n        val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n        y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n        score = kendall_tau(df_orders.loc[y_dummy.index], y_dummy)\n        print(\"Preds score\", score)\n        \n        \n        torch.save(model.state_dict(), \"./model.bin\")        \n        del pred, inputs, target, loss, \n        gc.collect()\n        torch.cuda.empty_cache()\n        \n    return model, y_pred\n\n\nmodel = MarkdownModel()\nmodel = model.cuda()\nmodel, y_pred = train(model, train_loader, val_loader, epochs=EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model_path, ckpt_path):\n    model = MarkdownModel(model_path)\n    model = model.cuda()\n    model.eval()\n    model.load_state_dict(torch.load(ckpt_path))\n    BS = 32\n    NW = 2\n    MAX_LEN = 64\n    test_df[\"pct_rank\"] = 0\n    test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), md_max_len=64,total_max_len=512, model_name_or_path=model_path, fts=test_fts)\n    test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n                              pin_memory=False, drop_last=False)\n    _, y_test = validate(model, test_loader)\n    return y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load test dataset","metadata":{}},{"cell_type":"code","source":"paths_test = list((data_dir/'test').glob('*.json'))\nnotebook_test = [\n    read_notebook(path) for path in paths_test\n]\ntest_df = (\n    pd.concat(notebook_test)\n    .set_index('id',append=True)\n    .swaplevel()\n    .sort_index(level='id',sort_remaining=False)\n).reset_index()\ntest_df[\"pct_rank\"] = 0\ntest_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\ntest_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\ntest_fts = get_features(test_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tiến hành predict kết quả từ model vừa huấn luyện được","metadata":{}},{"cell_type":"code","source":"model_path = \"../input/huggingface-code-models/codebert-base\"\nckpt_path = \"./model.bin\"\ny_test = predict(model_path, ckpt_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save file submission\n\nTiến hành lưu lại file submission và đặt tên là **submission1** để phân biệt với file submission2 bên dưới","metadata":{}},{"cell_type":"code","source":"test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test\nsub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\nsub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\nsub_df.to_csv(\"./submission1.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DistilBert baseline\n\n# Ý tưởng: \nSử dụng DistilBert để tokenize trong MarkdownDataset class và cấu hình lại Distilbert model cho phù hợp với bài toán trong MarkdownModel class.\n\n**Lưu ý**: phần DistilBert có dùng lại một số hàm đã được code từ phần phía trên.","metadata":{}},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"from transformers import DistilBertModel, DistilBertTokenizer\nfrom sklearn.metrics import mean_squared_error","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"data_dir = Path('../input/AI4Code')\nBERT_PATH = '../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data\n\nLoad toàn bộ file dùng để train (`LIMIT = None`)\n\n**Trên thực tế**, nhóm đã load 100.000 file dùng để train (`LIMIT = 100000`) bởi vì giới hạn về mặt phần cứng trên Kaggle","metadata":{}},{"cell_type":"code","source":"LIMIT = None\npaths_train = list((data_dir / 'train').glob('*.json'))[:LIMIT]\nnotebooks_train = [\n    read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n]\ndf = (\n    pd.concat(notebooks_train)\n    .set_index('id', append=True)\n    .swaplevel()\n    .sort_index(level='id', sort_remaining=False)\n)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Quan sát sơ lược dữ liệu vừa đọc được","metadata":{}},{"cell_type":"code","source":"df_orders = pd.read_csv(\n    data_dir / 'train_orders.csv',\n    index_col='id',\n    squeeze=True,\n).str.split()\ndf_orders","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Phần preprocessing bên dưới tương tự với phần preprocessing của mô hình bên trên (codebert)","metadata":{}},{"cell_type":"code","source":"df_orders_ = df_orders.to_frame().join(\n    df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n    how='right',\n)\nranks = {}\nfor id_,cell_order,cell_id in df_orders_.itertuples():\n    ranks[id_] = {'cell_id': cell_id,'rank': get_ranks(cell_order,cell_id)}\ndf_ranks = (\n    pd.DataFrame\n    .from_dict(ranks,orient='index' )\n    .rename_axis('id')\n    .apply(pd.Series.explode)\n    .set_index('cell_id', append=True)\n)\ndf_ranks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.reset_index().merge(df_ranks, on=[\"id\", \"cell_id\"]).merge(df_ancestors, on=[\"id\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"pct_rank\"] = df[\"rank\"] / df.groupby(\"id\")[\"cell_id\"].transform(\"count\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split data train, test, val","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupShuffleSplit\nNVALID = 0.1 # size of validate\nsplitter = GroupShuffleSplit(n_splits=1,test_size=NVALID,random_state=212)\n\ntrain_ind,val_ind = next(splitter.split(df,groups=df[\"ancestor_id\"]))\ntrain_df = df.loc[train_ind].reset_index(drop=True)\nval_df = df.loc[val_ind].reset_index(drop=True)\nval_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_mark = train_df[train_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)\nval_df_mark = val_df[val_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MarkdownModel class\n\nThứ tự các layer bao gồm:\n- DistilBertModel\n- Linear(768, 64)\n- Dropout 0.1\n- Linear(64, 1)\n- Sigmoid","metadata":{}},{"cell_type":"code","source":"class MarkdownModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.distill_bert = DistilBertModel.from_pretrained(BERT_PATH)\n        self.top1 = nn.Linear(768,64)\n        self.top2 = nn.Linear(64,1)\n        self.dropout = nn.Dropout(p=0.1)\n    def forward(self,ids,mask):\n        x = self.distill_bert(ids,mask)[0][:,0,:]\n        x = self.top1(x)\n        x = self.dropout(x)\n        x = self.top2(x)\n        x = torch.sigmoid(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MarkdownDataset class\n\nSử dụng kết quả của DistilBert để tokenize dữ liệu với chiều dài tối đa là 128.","metadata":{}},{"cell_type":"code","source":"class MarkdownDataset(Dataset):\n    def __init__(self,df,max_len):\n        super().__init__()\n        self.df = df.reset_index(drop=True)\n        self.max_len = max_len\n        self.tokenizer = DistilBertTokenizer.from_pretrained('../input/huggingface-bert/bert-large-uncased')\n    def __getitem__(self,index):\n        row = self.df.iloc[index]\n        inputs = tokenizer.encode_plus(\n            row.source,\n            add_special_tokens=True,\n            max_length = 128,\n            padding=\"max_length\",\n            return_token_type_ids=True,\n            truncation=True\n        )\n        ids = torch.LongTensor(inputs['input_ids'])\n        mask = torch.LongTensor(inputs['attention_mask'])\n        return ids,mask, torch.FloatTensor([row['pct_rank']])\n    def __len__(self):\n        return self.df.shape[0]\ntrain_ds = MarkdownDataset(train_df_mark,max_len=128)\nval_ds = MarkdownDataset(val_df_mark,max_len=128)\nlen(val_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train and test data loader.","metadata":{}},{"cell_type":"code","source":"BATCH = 16\nNW = 2\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, num_workers=NW,\n                          pin_memory=False, drop_last=True)\nval_loader = DataLoader(val_ds, batch_size=BATCH, shuffle=True, num_workers=NW,\n                          pin_memory=False, drop_last=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learning rate at specific epochs\ndef adjust_lr(optimizer, epoch):\n    if epoch < 1:\n        lr = 5e-5\n    elif epoch < 2:\n        lr = 4e-5\n    elif epoch < 5:\n        lr = 3e-5\n    else:\n        lr = 2e-5\n\n    for p in optimizer.param_groups:\n        p['lr'] = lr\n    return lr\n\n# Define optimizer\ndef get_optimizer(net):\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n                                 eps=1e-08)\n    return optimizer\n\ndef read_data(data):\n    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n# Predicts and labels \ndef validate(model, val_loader):\n    model.eval()\n    tbar = tqdm(val_loader, file=sys.stdout)\n    \n    preds = []\n    labels = []\n\n    with torch.no_grad():\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            pred = model(inputs[0], inputs[1])\n\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n    \n    return np.concatenate(labels), np.concatenate(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train\n\nTrain mô hình với 3 epoch.","metadata":{}},{"cell_type":"code","source":"def train(model, train_loader, val_loader, epochs):\n    np.random.seed(0)\n    # Optimizer defined above\n    optimizer = get_optimizer(model)\n    # Using L1 loss\n    criterion = torch.nn.L1Loss()\n    \n    for e in range(epochs):   \n        model.train()\n        tbar = tqdm(train_loader, file=sys.stdout)\n        \n        lr = adjust_lr(optimizer, e)\n        \n        loss_list = []\n        preds = []\n        labels = []\n\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            optimizer.zero_grad()\n            pred = model(*inputs)\n            loss = criterion(pred, target)\n            loss.backward()\n            optimizer.step()\n            \n            loss_list.append(loss.detach().cpu().item())\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n            \n            avg_loss = np.round(np.mean(loss_list), 4)\n\n            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n      \n        y_val, y_pred = validate(model, val_loader)\n        print(len(y_pred),len(y_val))\n\n        val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n        val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n\n        y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n        score = kendall_tau(df_orders.loc[y_dummy.index], y_dummy)\n\n        print('score : ', score)\n\n        output_model_file = f\"./my_own_model_file_{e}_{np.round(score, 5)}.bin\"\n        model_to_save = model.module if hasattr(model, 'module') else model\n        torch.save(model_to_save.state_dict(), output_model_file)\n                        \n        print(\"Validation MSE:\", np.round(mean_squared_error(y_val, y_pred), 4))\n        print()\n        \n        #optimize memory\n        del inputs, target\n        gc.collect()\n        \n    return model, y_pred\n\nmodel = MarkdownModel()\nmodel = model.cuda()\nmodel, y_pred = train(model, train_loader, val_loader, epochs=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load test data set\n\nThực hiện load lại test data set, bởi vì lượng test data khá nhỏ và để đảm bảo file test không hề bị modify nên nhóm sẽ load lại test dataset","metadata":{}},{"cell_type":"code","source":"paths_test = list((data_dir/'test').glob('*.json'))\nnotebook_test = [\n    read_notebook(path) for path in paths_test\n]\ntest_df = (\n    pd.concat(notebook_test)\n    .set_index('id',append=True)\n    .swaplevel()\n    .sort_index(level='id',sort_remaining=False)\n).reset_index()\ntest_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dự đoán kết quả của tập test.","metadata":{}},{"cell_type":"code","source":"# dummy collumns to fit MarkdownDataset\ntest_df[\"pct_rank\"] = 0\ntest_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\ntest_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n# create dataset interence and loader inference\ntest_ds = MarkdownDataset(test_df[test_df[\"cell_type\"]==\"markdown\"].reset_index(drop=True),max_len=128)\ntest_loader = DataLoader(test_ds,batch_size=BATCH,shuffle=False,num_workers=NW,\n                        pin_memory=False,drop_last=False)\n\ny_test = validate(model,test_loader)[1]\ntest_df.loc[test_df[\"cell_type\"]==\"markdown\",\"pred\"] = y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sắp xếp các cell theo thứ tự đã predict và lưu kết quả vào file `submission2.csv`.","metadata":{}},{"cell_type":"code","source":"sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\nsub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\nsub_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv(\"submission2.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble\n\n* Từ kết quả 2 model trên ta lấy trung bình vị trí (thứ tự cell trong trong notebook) theo tỉ lệ 0.25:0.75 giữa của 2 kết quả.\n* Sau đó sắp xếp lại và lưu vào một file kết quả cuối cùng","metadata":{}},{"cell_type":"code","source":"df_1 = pd.read_csv('submission2.csv')\ndf_2 = pd.read_csv('submission1.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_samples = []\nfor sample_idx in range(len(df_1)):\n    sample_1 = {k: v for v, k in enumerate(df_1.iloc[sample_idx]['cell_order'].split(' '))}\n    sample_2 = {k: v for v, k in enumerate(df_2.iloc[sample_idx]['cell_order'].split(' '))}\n    for key in sample_1: sample_1[key] = ( (sample_1[key] * 0.25) + (sample_2[key] * 0.75) )\n    new_samples.append(' '.join([i[0] for i in list(sorted(sample_1.items(), key=lambda x:x[1]))]))\ndf_1['cell_order'] = new_samples","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lưu lại file submission hoàn chỉnh","metadata":{}},{"cell_type":"code","source":"df_1.to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Kết quả trên Bảng xếp hạng\n\n[Result link](https://drive.google.com/file/d/1CUsJVvr_YvC5yjIndCSzA-J0VgGrnRJi/view?usp=sharing)\n\n[Result link (backup)](https://drive.google.com/file/d/16vpEZseVqGdHZsOnw3opQbNUjmR8iMBn/view?usp=sharing)","metadata":{}},{"cell_type":"markdown","source":"![image](https://drive.google.com/uc?export=view&id=1CUsJVvr_YvC5yjIndCSzA-J0VgGrnRJi)","metadata":{}},{"cell_type":"markdown","source":"# Nhận xét:\n- Kết quả trên bảng xếp hạng tương đối ổn.\n- Mặc dù kết quả ổn, tuy nhiên, cả 2 cách tiếp cận trên vẫn chưa tận dụng tối đa tính chất của các file code (code cell luôn đảm bảo thứ tự).\n- Thời gian train các mô hình khá lâu, sử dụng tối đa thời gian và cấu hình cho phép của Kaggle (12h/1 lần train) vẫn chỉ có thể train được 1 phần nhỏ của dữ liệu.\n- Tồn tại nhiều loại ngôn ngữ khác nhau trong dữ liệu, theo [discussion](https://www.kaggle.com/competitions/AI4Code/discussion/329783). Do đó việc train 1 phần nhỏ và không có sự phân loại có thể làm giảm sự chính xác.","metadata":{}},{"cell_type":"markdown","source":"# Tài liệu tham khảo:\n\n- **[Stronger baseline with code cells](https://www.kaggle.com/code/suicaokhoailang/stronger-baseline-with-code-cells)** by [suicaokhoailang](https://www.kaggle.com/suicaokhoailang)\n- **[AI4Code Pytorch DistilBert Baseline](https://www.kaggle.com/code/aerdem4/ai4code-pytorch-distilbert-baseline)** by [Ahmet Erdem](https://www.kaggle.com/aerdem4)\n- **[Getting Started with AI4Code](https://www.kaggle.com/code/ryanholbrook/getting-started-with-ai4code)**","metadata":{}}]}